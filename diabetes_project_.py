# -*- coding: utf-8 -*-
"""diabetes project .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i6Gz1kHf0UNZTuc2jvUOQHZSO1Vd0Fso

in this python diabetes project first of all
 Imports the pandas library.
Reads the CSV file located at the given path.
"""

import pandas as pd
dia=pd.read_csv("/content/drive/MyDrive/diabetes.csv")
dia

print(dia.head())

"""Displays the first 5 rows of the dataset for a quick overview."""

dia.describe()

"""The .describe() method in pandas provides a statistical summary of the numerical columns in the dataset."""

dia.info()

"""The .info() method in pandas provides a concise summary of the dataset, including details about the structure of the data and its columns.

**checking nul values**
"""

dia.isna().sum()

"""The .isna() method in pandas is used to check for missing values (NaNs) in a DataFrame. When combined with .sum(), it provides a count of missing values in each column.

**chechking duplicate values**

To check for duplicate values in a DataFrame, you can use the .duplicated() method in pandas. Here's how to do it:
"""

dia.duplicated().sum()

"""**Define Features and Target Variable**"""

features=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI',
'DiabetesPedigreeFunction','Age']
target = 'Outcome'

print("X = dia[features]")
print("y = dia[target]")

"""**Data vissulization**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
dia = pd.read_csv("/content/drive/MyDrive/diabetes.csv")

plt.figure(figsize=(12, 6))
sns.countplot(x='Outcome', data=dia, hue='Outcome', palette={0: 'lightblue', 1: 'orange'}, dodge=False)
plt.xlabel('Outcome')
plt.ylabel('Count')
plt.show()

"""***Observing Outliers ***"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# Set the size of the plot
plt.figure(figsize=(20, 12))
for i, column in enumerate(dia.columns[:-1], 1):  # Exclude the 'Outcome' column
    plt.subplot(3, 3, i)
    sns.boxplot(y=column, data=dia)
    plt.title(f'Boxplot of {column}')

plt.tight_layout()
plt.show()

"""
**Pairplot for all columns**:"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
sns.pairplot(dia, hue='Outcome', palette='viridis')  # 'hue' colors the plots based on the 'Outcome' column
plt.show()

"""**Histograms of All columns**"""

import pandas as pd
import matplotlib.pyplot as plt
dia.hist(figsize=(12, 10), bins=15, color='skyblue', edgecolor='black')
plt.hist(dia['Outcome'], bins=12, color='skyblue', edgecolor='black')

plt.tight_layout()  # Adjust subplots to fit into the figure area.
plt.show()

"""***Heatmaps' ***"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')
corr_matrix = data.corr()
# Generate a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap of Diabetes Dataset Features')
plt.show()

"""**Feature Scaling**

"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
X = dia.drop(columns=['Outcome'])
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)
print(X_scaled_df.head())

X=dia.drop(columns=["Outcome"],axis=1).values
Y=dia[["Outcome"]].values

"""**Normalize**"""

X=X/X.max()

from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=0.20,random_state=50)

(ytest==1).sum()

(ytest==0).sum()

"""**Train-Test Split**"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Define the feature set (X) and the target variable (y)
X = dia.drop(columns=['Outcome'])
y = dia['Outcome']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-Test Split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Check the shapes of train and test sets
print("Training set shape (X):", X_train.shape)
print("Testing set shape (X):", X_test.shape)
print("Training set shape (y):", y_train.shape)
print("Testing set shape (y):", y_test.shape)

"""**train-test split output**"""

print(f"Train set: {len(X_train) / len(X_scaled) * 100:.0f}%")
print(f"Test set: {len(X_test) / len(X_scaled) * 100:.0f}%")

"""**Check for Imbalanced Data:**"""

from collections import Counter
print(Counter(y_train))

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Check the distribution of the 'Outcome' column
plt.figure(figsize=(8, 6))
sns.countplot(x='Outcome', data=data)
plt.title('Distribution of Outcome')
plt.xlabel('Outcome')
plt.ylabel('Count')
plt.show()

plt.show()

"""# Balance the Dataset:"""

from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X_train, y_train)

"""**Correlation between diabetes and all variables**"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load your dataset
try:
    data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')
except FileNotFoundError as e:
    print("File not found. Please check the path and try again.")
    raise e

# Display the first few rows of the dataframe to understand its structure
print(data.head())

# Compute the correlation matrix
corr_matrix = data.corr()

# Display the correlation matrix
print(corr_matrix)

# Visualize the correlation matrix using a heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix of Diabetes Dataset')
plt.show()

# Extract the correlation values of 'Outcome' with all other variables
outcome_corr = corr_matrix['Outcome'].sort_values(ascending=False)
print(outcome_corr)

# Visualize the correlation of each feature with the 'Outcome' variable using a bar plot
plt.figure(figsize=(10, 6))
sns.barplot(x=outcome_corr.index, y=outcome_corr.values, palette='coolwarm')
plt.xlabel('Features')
plt.ylabel('Correlation with Outcome')
plt.title('Correlation of Features with Outcome (Diabetes)')
plt.xticks(rotation=45)
plt.show()

"""***Vissulization sll features in diabetes ***

**` Age by Diabetes Outcome `**
"""

import matplotlib.pyplot as plt

# Group the data by 'Outcome' and calculate the mean 'Age' for each outcome
outcome_age_mean = dia.groupby('Outcome')['Age'].mean()

# Plotting the bar graph
plt.bar(outcome_age_mean.index, outcome_age_mean.values, color='skyblue')
plt.xlabel('Outcome')
plt.ylabel('Average Age')
plt.title('Average Age by Outcome')
plt.xticks([0, 1], ['No Diabetes', 'Diabetes'])
plt.show()

"""***Glucose by outcomes ***"""

import matplotlib.pyplot as plt

# Plotting the bar graph
plt.bar(dia['Outcome'], dia['Glucose'])
plt.xlabel('Outcome')
plt.ylabel('Glucose')
plt.title('Glucose levels by Outcome')
plt.xticks([0, 1], ['Non-Diabetic', 'Diabetic'])
plt.show()

"""**Blood pressure by outcomes**"""

import matplotlib.pyplot as plt

# Group the data by 'Outcome' and calculate the mean 'BloodPressure'
grouped_data = dia.groupby('Outcome')['BloodPressure'].mean().reset_index()

# Plotting the bar graph
plt.bar(grouped_data['Outcome'], grouped_data['BloodPressure'], color='skyblue')
plt.xlabel('Outcome')
plt.ylabel('Average Blood Pressure')
plt.title('Average Blood Pressure by Outcome')
plt.xticks([0, 1], ['No Diabetes', 'Diabetes'])
plt.show()

"""**skinthickness by outcomes**"""

import matplotlib.pyplot as plt

# Group the data by 'Outcome' and calculate the mean of 'SkinThickness' for each group
outcome_mean_skinthickness = dia.groupby('Outcome')['SkinThickness'].mean()

# Plotting the bar graph
plt.bar(outcome_mean_skinthickness.index, outcome_mean_skinthickness.values, color='skyblue')
plt.xlabel('Outcome')
plt.ylabel(' Skin Thickness')
plt.title(' Skin Thickness by Outcome')
plt.xticks([0, 1], ['No Diabetes', 'Diabetes'])
plt.show()

"""**insulin level by outcomes**"""

import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'dia' is your DataFrame
dia=pd.read_csv("/content/drive/MyDrive/diabetes.csv")

# Group the data by 'Outcome' and calculate the mean 'Insulin' for each group
outcome_insulin = dia.groupby('Outcome')['Insulin'].mean()

# Plotting the bar graph
plt.bar(outcome_insulin.index, outcome_insulin.values, color=['blue', 'red'])
plt.xlabel('Outcome')
plt.ylabel(' Insulin Level')
plt.title(' Insulin Level by Outcome')
plt.xticks(outcome_insulin.index, ['No Diabetes', 'Diabetes'])
plt.show()

"""**BMI by outcomes**"""

import matplotlib.pyplot as plt

# Group the data by 'Outcome' and calculate the mean BMI for each outcome
outcome_bmi_mean = dia.groupby('Outcome')['BMI'].mean()

# Plotting the bar graph
plt.bar(outcome_bmi_mean.index, outcome_bmi_mean.values, color='skyblue')
plt.xlabel('Outcome')
plt.ylabel('BMI')
plt.title('Average BMI by Outcome')
plt.xticks(outcome_bmi_mean.index, ['Non-Diabetic', 'Diabetic'])
plt.show()

"""**DiabetesPedigreeFunction by outcomes**"""

import matplotlib.pyplot as plt
import pandas as pd

# Assuming dia is your DataFrame containing the data
# Assuming 'Outcome' is a column in your DataFrame
# Assuming 'DiabetesPedigreeFunction' is a column in your DataFrame

# Group by 'Outcome' and calculate the mean of 'DiabetesPedigreeFunction'
data = dia.groupby('Outcome')['DiabetesPedigreeFunction'].mean().reset_index()

# Plotting the bar graph
plt.figure(figsize=(8, 6))
plt.bar(data['Outcome'], data['DiabetesPedigreeFunction'], color='skyblue')
plt.xlabel('Outcome')
plt.ylabel(' DiabetesPedigreeFunction')
plt.title(' DiabetesPedigreeFunction by Outcome')
plt.xticks(data['Outcome'])
plt.show()

"""#  Statistics of the dia DataFrame"""

import matplotlib.pyplot as plt
stats = dia.describe().drop('count')
plt.figure(figsize=(6.4, 4.8))
stats.plot(kind='bar', ax=plt.gca())
plt.title(' Statistics of dia DataFrame')
plt.ylabel('Value')
plt.xticks(rotation=45)
plt.legend(title='Statistics')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

g = [1, 2, 3, 4, 5, 6, 7, 8]
labels = ["Pregnancies", "Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI", "Age", "Outcome"]

plt.pie(g, labels=labels)
plt.figure(figsize=(6.4, 4.8))
plt.show()

"""**Train and Evaluate Multiple Models**

**Logistic Regression Model**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from sklearn.model_selection import train_test_split

 Check the dimensions of X_scaled and y
print(f"Features shape: {X_scaled.shape}")
print(f"Target shape: {y.shape}")

# Ensure that X_scaled and y have the same number of samples
if X_scaled.shape[0] != y.shape[0]:
    raise ValueError("Feature matrix and target variable have inconsistent number of samples.")

# Train-Test-Validation Split (60% train, 20% validation, 20% test)
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize and train the Logistic Regression model
log_reg = LogisticRegression(random_state=42, max_iter=1000)
log_reg.fit(X_train, y_train)

# Predictions
y_pred_train = log_reg.predict(X_train)
y_pred_valid = log_reg.predict(X_valid)
y_pred_test = log_reg.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, y_pred_train)
valid_accuracy = accuracy_score(y_valid, y_pred_valid)
test_accuracy = accuracy_score(y_test, y_pred_test)

# Print the accuracy scores
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {valid_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Confusion matrix and recall
conf_matrix = confusion_matrix(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test, average='weighted')  # Use 'weighted' for multi-class classification

print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)

# Confusion Matrix Plot
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=log_reg.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
accuracies = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']

plt.figure(figsize=(8, 6))
plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
plt.xlabel('Dataset')
plt.ylabel('Accuracy')
plt.title('Model Accuracy on Different Datasets')
plt.show()

"""**Random Forest Model**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from sklearn.model_selection import train_test_split

# Check the dimensions of X_scaled and y
print(f"Features shape: {X_scaled.shape}")
print(f"Target shape: {y.shape}")

# Ensure that X_scaled and y have the same number of samples
if X_scaled.shape[0] != y.shape[0]:
    raise ValueError("Feature matrix and target variable have inconsistent number of samples.")

# Train-Test-Validation Split (60% train, 20% validation, 20% test)
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize and train the model with tuned hyperparameters
rf = RandomForestClassifier(random_state=42, max_depth=10, min_samples_split=10, n_estimators=100)
rf.fit(X_train, y_train)

# Predictions
y_pred_train = rf.predict(X_train)
y_pred_valid = rf.predict(X_valid)
y_pred_test = rf.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, y_pred_train)
valid_accuracy = accuracy_score(y_valid, y_pred_valid)
test_accuracy = accuracy_score(y_test, y_pred_test)

# Print the accuracy scores
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {valid_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Confusion matrix and recall
conf_matrix = confusion_matrix(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test, average='weighted')  # Use 'weighted' for multi-class classification

print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)

# Confusion Matrix Plot
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
accuracies = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']

plt.figure(figsize=(8, 6))
plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
plt.xlabel('Dataset')
plt.ylabel('Accuracy')
plt.title('Model Accuracy ')
plt.show()

"""# **`KNN Model `**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from sklearn.model_selection import train_test_split

# Example Data Preparation (ensure X_scaled and y have the same number of samples)
# Replace this with your actual data loading and preprocessing steps
# X_scaled = ... # Feature matrix after scaling or preprocessing
# y = ... # Target variable

# Check the dimensions of X_scaled and y
print(f"Features shape: {X_scaled.shape}")
print(f"Target shape: {y.shape}")

# Ensure that X_scaled and y have the same number of samples
if X_scaled.shape[0] != y.shape[0]:
    raise ValueError("Feature matrix and target variable have inconsistent number of samples.")

# Train-Test-Validation Split (60% train, 20% validation, 20% test)
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize and train the KNN model with tuned hyperparameters
knn = KNeighborsClassifier(n_neighbors=5)  # You can tune n_neighbors and other parameters
knn.fit(X_train, y_train)

# Predictions
y_pred_train = knn.predict(X_train)
y_pred_valid = knn.predict(X_valid)
y_pred_test = knn.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, y_pred_train)
valid_accuracy = accuracy_score(y_valid, y_pred_valid)
test_accuracy = accuracy_score(y_test, y_pred_test)

# Print the accuracy scores
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {valid_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Confusion matrix and recall
conf_matrix = confusion_matrix(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test, average='weighted')  # Use 'weighted' for multi-class classification

print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)

# Confusion Matrix Plot
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=knn.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
accuracies = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']

plt.figure(figsize=(8, 6))
plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
plt.xlabel('Dataset')
plt.ylabel('Accuracy')
plt.title('Model Accuracy on Different Datasets')
plt.show()

"""***Decision Tree Classifier ***"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from sklearn.model_selection import train_test_split

# Example Data Preparation (ensure X_scaled and y have the same number of samples)
# Replace this with your actual data loading and preprocessing steps
# X_scaled = ... # Feature matrix after scaling or preprocessing
# y = ... # Target variable

# Check the dimensions of X_scaled and y
print(f"Features shape: {X_scaled.shape}")
print(f"Target shape: {y.shape}")

# Ensure that X_scaled and y have the same number of samples
if X_scaled.shape[0] != y.shape[0]:
    raise ValueError("Feature matrix and target variable have inconsistent number of samples.")

# Train-Test-Validation Split (60% train, 20% validation, 20% test)
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize and train the Decision Tree model
dt = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=10)
dt.fit(X_train, y_train)

# Predictions
y_pred_train = dt.predict(X_train)
y_pred_valid = dt.predict(X_valid)
y_pred_test = dt.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, y_pred_train)
valid_accuracy = accuracy_score(y_valid, y_pred_valid)
test_accuracy = accuracy_score(y_test, y_pred_test)

# Print the accuracy scores
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {valid_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Confusion matrix and recall
conf_matrix = confusion_matrix(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test, average='weighted')  # Use 'weighted' for multi-class classification

print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)

# Confusion Matrix Plot
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=dt.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
accuracies = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']

plt.figure(figsize=(8, 6))
plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
plt.xlabel('Dataset')
plt.ylabel('Accuracy')
plt.title('Model Accuracy on Different Datasets')
plt.show()

# Placeholder data for line plot
# Replace these lists with your actual data
iterations = list(range(1, 15))  # Example range of iterations or parameter values
Train_scores = np.random.rand(14)  # Example training scores, replace with actual data
Test_scores = np.random.rand(14)   # Example test scores, replace with actual data

plt.figure(figsize=(12, 5))
sns.lineplot(x=iterations, y=Train_scores, marker='*', label='Train Scores')
sns.lineplot(x=iterations, y=Test_scores, marker='o', label='Test Scores')
plt.xlabel('Iterations or Parameter Values')
plt.ylabel('Scores')
plt.title('Training and Test Scores over Iterations')
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.ndimage import gaussian_filter1d

# Example data for iterations and scores
iterations = np.arange(1, 15)  # Example range of iterations or parameter values
Train_scores = np.random.rand(14)  # Example training scores (replace with actual data)
Test_scores = np.random.rand(14)   # Example test scores (replace with actual data)

# Example of error values (you can replace these with actual standard deviation values or errors)
Train_error = np.random.rand(14) * 0.05  # Small errors for demonstration
Test_error = np.random.rand(14) * 0.05

# Smoothing the lines (using Gaussian smoothing to reduce noise)
Train_scores_smooth = gaussian_filter1d(Train_scores, sigma=1)
Test_scores_smooth = gaussian_filter1d(Test_scores, sigma=1)

# Plotting with error bars and smoothed lines
plt.figure(figsize=(12, 6))

# Plot the smoothed training and test scores
plt.plot(iterations, Train_scores_smooth, label='Train Scores (smoothed)', marker='*', color='blue')
plt.plot(iterations, Test_scores_smooth, label='Test Scores (smoothed)', marker='o', color='orange')

# Adding error bars
plt.errorbar(iterations, Train_scores, yerr=Train_error, fmt='o', color='blue', alpha=0.3, label='Train Error')
plt.errorbar(iterations, Test_scores, yerr=Test_error, fmt='o', color='orange', alpha=0.3, label='Test Error')

# Adding annotations for the highest test score
max_test_idx = np.argmax(Test_scores)
plt.annotate(f'Max Test Score: {Test_scores[max_test_idx]:.2f}',
             xy=(iterations[max_test_idx], Test_scores[max_test_idx]),
             xytext=(iterations[max_test_idx], Test_scores[max_test_idx] + 0.1),
             arrowprops=dict(facecolor='black', shrink=0.05))

# Labels and titles
plt.xlabel('Iterations or Parameter Values')
plt.ylabel('Scores')
plt.title('Training and Test Scores with Smoothing and Error Bars')

# Adding a legend
plt.legend()

# Displaying the plot
plt.grid(True)
plt.show()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from sklearn.model_selection import train_test_split

# Example Data Preparation (ensure X_scaled and y have the same number of samples)
# Replace this with your actual data loading and preprocessing steps
# X_scaled = ... # Feature matrix after scaling or preprocessing
# y = ... # Target variable

# Check the dimensions of X_scaled and y
print(f"Features shape: {X_scaled.shape}")
print(f"Target shape: {y.shape}")

# Ensure that X_scaled and y have the same number of samples
if X_scaled.shape[0] != y.shape[0]:
    raise ValueError("Feature matrix and target variable have inconsistent number of samples.")

# Train-Test-Validation Split (60% train, 20% validation, 20% test)
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize and train the Decision Tree model
dt = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=10)
dt.fit(X_train, y_train)

# Predictions
y_pred_train = dt.predict(X_train)
y_pred_valid = dt.predict(X_valid)
y_pred_test = dt.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, y_pred_train)
valid_accuracy = accuracy_score(y_valid, y_pred_valid)
test_accuracy = accuracy_score(y_test, y_pred_test)

# Print the accuracy scores
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {valid_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Confusion matrix and recall
conf_matrix = confusion_matrix(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test, average='weighted')  # Use 'weighted' for multi-class classification

print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)

# Confusion Matrix Plot
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=dt.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
accuracies = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']

plt.figure(figsize=(8, 6))
plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
plt.xlabel('Dataset')
plt.ylabel('Accuracy')
plt.title('Model Accuracy on Different Datasets')
plt.show()

# Placeholder data for line plot
# Replace these lists with your actual data
iterations = list(range(1, 15))  # Example range of iterations or parameter values
Train_scores = np.random.rand(14)  # Example training scores, replace with actual data
Test_scores = np.random.rand(14)   # Example test scores, replace with actual data

plt.figure(figsize=(12, 5))
sns.lineplot(x=iterations, y=Train_scores, marker='*', label='Train Scores')
sns.lineplot(x=iterations, y=Test_scores, marker='o', label='Test Scores')
plt.xlabel('Iterations or Parameter Values')
plt.ylabel('Scores')
plt.title('Training and Test Scores over Iterations')
plt.legend()
plt.show()

"""**Gradient Boosting Algorithm**"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV, train_test_split

# Use early stopping
from sklearn.model_selection import train_test_split

# Split the data
xtrain, xvalid, ytrain, yvalid = train_test_split(xtrain, ytrain, test_size=0.2, random_state=42)

# Grid search with early stopping
param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=1)
grid_search.fit(xtrain, ytrain)

# Best parameters
best_params = grid_search.best_params_
print(f"Best Parameters: {best_params}")

# Train the model with the best parameters
gb_model = GradientBoostingClassifier(**best_params, random_state=42)
gb_model.fit(xtrain, ytrain)

# Evaluate the model
train_accuracy = accuracy_score(ytrain, gb_model.predict(xtrain))
valid_accuracy = accuracy_score(yvalid, gb_model.predict(xvalid))
test_accuracy = accuracy_score(ytest, gb_model.predict(xtest))
print(f"Training Accuracy: {train_accuracy}")
print(f"Validation Accuracy: {valid_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# Confusion Matrix
cm = confusion_matrix(ytest, gb_model.predict(xtest))
cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gb_model.classes_)
cm_display.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
epochs = range(1, 301, 10)
train_accuracies = []
valid_accuracies = []
test_accuracies = []

for i in epochs:
    gb_model = GradientBoostingClassifier(n_estimators=i, learning_rate=best_params['learning_rate'],
                                          max_depth=best_params['max_depth'], min_samples_split=best_params['min_samples_split'], random_state=42)
    gb_model.fit(xtrain, ytrain)
    train_accuracies.append(accuracy_score(ytrain, gb_model.predict(xtrain)))
    valid_accuracies.append(accuracy_score(yvalid, gb_model.predict(xvalid)))
    test_accuracies.append(accuracy_score(ytest, gb_model.predict(xtest)))

plt.figure(figsize=(10, 6))
plt.plot(epochs, train_accuracies, label='Training Accuracy')
plt.plot(epochs, valid_accuracies, label='Validation Accuracy')
plt.plot(epochs, test_accuracies, label='Test Accuracy')
plt.xlabel('Number of Estimators')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Number of Estimators')
plt.legend()
plt.grid(True)
plt.show()

"""**SVM model**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score, roc_curve, precision_recall_curve, auc

# Load your dataset
try:
    data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')
except FileNotFoundError as e:
    print("File not found. Please check the path and try again.")
    raise e

# Check the first few rows of the dataframe to understand its structure
print(data.head())

# Display the value counts for the 'Outcome' column
print(data['Outcome'].value_counts())

# Define features and target
target_column = 'Outcome'
X = data.drop(columns=[target_column])
y = data[target_column]

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize and train the SVM model
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)

# Make predictions
prediction5 = svm_model.predict(X_test)

# Calculate accuracy
accuracy5 = svm_model.score(X_test, y_test)
print('Model Accuracy:', accuracy5 * 100)

# Define the accuracies dictionary and store the rounded accuracy
accuracies = {}
accuracies['SVM'] = np.round(accuracy5 * 100, 3)
print(accuracies)

# Confusion matrix
cm1 = confusion_matrix(y_test, prediction5)
print(cm1)
ConfusionMatrixDisplay(confusion_matrix=cm1).plot()

# Classification report
print(classification_report(y_test, prediction5))

# Calculate ROC AUC
probs = svm_model.predict_proba(X_test)
probs = probs[:, 1]
auc5 = roc_auc_score(y_test, probs)
print('Area under the ROC Curve (AUC): %.2f' % auc5)

# Plot ROC Curve
fpr5, tpr5, _ = roc_curve(y_test, probs)
plt.figure()
plt.plot(fpr5, tpr5, label='SVM (area = %0.2f)' % auc5)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# Calculate Precision-Recall AUC
precision5, recall5, _ = precision_recall_curve(y_test, probs)
auc_score5 = auc(recall5, precision5)
print('Area under the PR Curve (AUCPR): %.2f' % auc_score5)

# Plot Precision-Recall Curve
plt.figure()
plt.plot(recall5, precision5, label='SVM (area = %0.2f)' % auc_score5)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTEENN

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')

# Check the first few rows of the dataframe to understand its structure
print(data.head())

# Replace 'Outcome' with the actual target column name if different
target_column = 'Outcome'

# Split the data into features (X) and target (y)
X = data.drop(target_column, axis=1)
y = data[target_column]

# Split the data into training and test sets
xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

# Balance the training data using SMOTE
smote = SMOTE(random_state=42)
xtrain_balanced, ytrain_balanced = smote.fit_resample(xtrain, ytrain)

# Feature scaling
scaler = StandardScaler()
xtrain_balanced = scaler.fit_transform(xtrain_balanced)
xtest = scaler.transform(xtest)

# Hyperparameter tuning for SVM
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']
}

grid_search = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)
grid_search.fit(xtrain_balanced, ytrain_balanced)

# Best parameters
best_params = grid_search.best_params_
print(f"Best Parameters: {best_params}")

# Train the model with the best parameters
svm_best = SVC(**best_params, probability=True, random_state=42)
svm_best.fit(xtrain_balanced, ytrain_balanced)

# Evaluate the model
train_accuracy = accuracy_score(ytrain_balanced, svm_best.predict(xtrain_balanced))
test_accuracy = accuracy_score(ytest, svm_best.predict(xtest))
print(f"Training Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# Confusion Matrix
cm = confusion_matrix(ytest, svm_best.predict(xtest))
cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svm_best.classes_)
cm_display.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

# Recall score
recall_svm = recall_score(ytest, svm_best.predict(xtest))
print('Recall:', recall_svm)

"""**Blancing training data using SMOTE techniques**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score, roc_curve, roc_auc_score
from imblearn.over_sampling import SMOTE

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')

# Check the first few rows of the dataframe to understand its structure
print(data.head())

# Replace 'Outcome' with the actual target column name if different
target_column = 'Outcome'

# Split the data into features (X) and target (y)
X = data.drop(target_column, axis=1)
y = data[target_column]

# Split the data into training and test sets
xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

# Balance the training data using SMOTE
smote = SMOTE(random_state=42)
xtrain_balanced, ytrain_balanced = smote.fit_resample(xtrain, ytrain)

# Feature scaling
scaler = StandardScaler()
xtrain_balanced = scaler.fit_transform(xtrain_balanced)
xtest = scaler.transform(xtest)

# Hyperparameter tuning for SVM
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']
}

grid_search = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)
grid_search.fit(xtrain_balanced, ytrain_balanced)

# Best parameters
best_params = grid_search.best_params_
print(f"Best Parameters: {best_params}")

# Train the model with the best parameters
svm_best = SVC(**best_params, probability=True, random_state=42)
svm_best.fit(xtrain_balanced, ytrain_balanced)

# Evaluate the model
train_accuracy = accuracy_score(ytrain_balanced, svm_best.predict(xtrain_balanced))
test_accuracy = accuracy_score(ytest, svm_best.predict(xtest))
print(f"Training Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# Confusion Matrix
cm = confusion_matrix(ytest, svm_best.predict(xtest))
cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svm_best.classes_)
cm_display.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

# Recall score
recall_svm = recall_score(ytest, svm_best.predict(xtest))
print('Recall:', recall_svm)

# ROC Curve
y_pred_proba = svm_best.predict_proba(xtest)[:, 1]
fpr, tpr, thresholds = roc_curve(ytest, y_pred_proba)
roc_auc = roc_auc_score(ytest, y_pred_proba)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score, roc_curve, precision_recall_curve, auc
from imblearn.under_sampling import RandomUnderSampler

# Load your dataset
try:
    data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')
except FileNotFoundError as e:
    print("File not found. Please check the path and try again.")
    raise e

# Check the first few rows of the dataframe to understand its structure
print(data.head())

# Display the value counts for the 'Outcome' column
print(data['Outcome'].value_counts())

# Define features and target
target_column = 'Outcome'
X = data.drop(columns=[target_column])
y = data[target_column]

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Apply Random Under-Sampling to balance the training data
rus = RandomUnderSampler(random_state=2)
X_train_balanced, y_train_balanced = rus.fit_resample(X_train, y_train)

# Initialize and train the SVM model on the balanced data
svm_model = SVC(probability=True)
svm_model.fit(X_train_balanced, y_train_balanced)

# Make predictions
predictions = svm_model.predict(X_test)

# Calculate accuracy
accuracy = svm_model.score(X_test, y_test)
print('Model Accuracy:', accuracy * 100)

# Define the accuracies dictionary and store the rounded accuracy
accuracies = {}
accuracies['SVM with Random Under-Sampling'] = np.round(accuracy * 100, 3)
print(accuracies)

# Confusion matrix
cm = confusion_matrix(y_test, predictions)
print(cm)
ConfusionMatrixDisplay(confusion_matrix=cm).plot()
plt.title('Confusion Matrix: SVM with Random Under-Sampling')
plt.show()

# Classification report
print(classification_report(y_test, predictions))

# Calculate ROC AUC
probs = svm_model.predict_proba(X_test)
probs = probs[:, 1]
auc_score = roc_auc_score(y_test, probs)
print('Area under the ROC Curve (AUC): %.2f' % auc_score)

# Plot ROC Curve
fpr, tpr, _ = roc_curve(y_test, probs)
plt.figure()
plt.plot(fpr, tpr, label='SVM with Random Under-Sampling (area = %0.2f)' % auc_score)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# Calculate Precision-Recall AUC
precision, recall, _ = precision_recall_curve(y_test, probs)
pr_auc = auc(recall, precision)
print('Area under the PR Curve (AUCPR): %.2f' % pr_auc)

# Plot Precision-Recall Curve
plt.figure()
plt.plot(recall, precision, label='SVM with Random Under-Sampling (area = %0.2f)' % pr_auc)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

"""**LightGBM  model**"""

pip install lightgbm

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Example data loading
# Load your dataset here
# df = pd.read_csv('your_dataset.csv')

# Example feature and target variable
# X = df.drop('target', axis=1)  # Features
# y = df['target']  # Target variable

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Ensure that y is a numpy array
y = np.array(Y)

print(f"Features shape: {X_scaled.shape}")
print(f"Target shape: {y.shape}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Example data loading
# Replace with actual data loading
# df = pd.read_csv('your_dataset.csv')
# X = df.drop('target', axis=1)  # Features
# y = df['target']  # Target variable

# Example Data Preparation
# Assume X and y are defined here
X = np.random.rand(100, 10)  # Replace with your actual features
y = np.random.randint(0, 2, 100)  # Replace with your actual target

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Check the dimensions of X_scaled and y
print(f"Features shape: {X_scaled.shape}")
print(f"Target shape: {y.shape}")

# Ensure that X_scaled and y have the same number of samples
if X_scaled.shape[0] != y.shape[0]:
    raise ValueError("Feature matrix and target variable have inconsistent number of samples.")

# Train-Test-Validation Split (60% train, 20% validation, 20% test)
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize and train the LightGBM model with tuned hyperparameters
lgbm = LGBMClassifier(random_state=42, max_depth=10, min_child_samples=10, n_estimators=100)
lgbm.fit(X_train, y_train)

# Predictions
y_pred_train = lgbm.predict(X_train)
y_pred_valid = lgbm.predict(X_valid)
y_pred_test = lgbm.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, y_pred_train)
valid_accuracy = accuracy_score(y_valid, y_pred_valid)
test_accuracy = accuracy_score(y_test, y_pred_test)

# Print the accuracy scores
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {valid_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Confusion matrix and recall
conf_matrix = confusion_matrix(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test, average='weighted')  # Use 'weighted' for multi-class classification

print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)

# Confusion Matrix Plot
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=lgbm.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
accuracies = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']

plt.figure(figsize=(8, 6))
plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
plt.xlabel('Dataset')
plt.ylabel('Accuracy')
plt.title('Model Accuracy')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, recall_score
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler

# Example data preparation (replace with your dataset)
X = np.random.rand(100, 10)  # Replace with your actual features
y = np.random.randint(0, 2, 100)  # Replace with your actual target

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-Test-Validation Split (60% train, 20% validation, 20% test)
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize LightGBM Classifier with initial hyperparameters
lgbm = LGBMClassifier(random_state=42, n_estimators=100, learning_rate=0.05, max_depth=8, min_child_samples=20)

# Fit model with early stopping to avoid overfitting
lgbm.fit(X_train, y_train,
         eval_set=[(X_valid, y_valid)],
         eval_metric='logloss',
         early_stopping_rounds=10,
         verbose=10)

# Predictions
y_pred_train = lgbm.predict(X_train)
y_pred_valid = lgbm.predict(X_valid)
y_pred_test = lgbm.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, y_pred_train)
valid_accuracy = accuracy_score(y_valid, y_pred_valid)
test_accuracy = accuracy_score(y_test, y_pred_test)

# Print the accuracy scores
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {valid_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Confusion matrix and recall
conf_matrix = confusion_matrix(y_test, y_pred_test)
recall = recall_score(y_test, y_pred_test, average='weighted')  # Use 'weighted' for multi-class classification

print(f"Recall: {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)

# Confusion Matrix Plot
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=lgbm.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Accuracy Chart
accuracies = [train_accuracy, valid_accuracy, test_accuracy]
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']

plt.figure(figsize=(8, 6))
plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1
plt.xlabel('Dataset')
plt.ylabel('Accuracy')
plt.title('LightGBM Model Accuracy')
plt.show()

"""**GAUSSIAN NAIVE_BAYES ALGORITHM**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'output' is the result of your diabetes prediction model
output = 1  # For demonstration purposes, assuming the patient has diabetes

if output == 1:
    print("The patient has Diabetes")
    # Generate a plot (for example, a bar plot)
    data = {'Glucose': [150], 'BloodPressure': [80], 'SkinThickness': [25], 'Insulin': [180], 'BMI': [30]}
    df = pd.DataFrame(data)
    plt.figure(figsize=(8, 6))
    sns.barplot(data=df)
    plt.title('Patient Attributes')
    plt.ylabel('Values')
    plt.xlabel('Attributes')
    plt.xticks(rotation=45)
    plt.show()
else:
    print("Healthy or normal person/lady")

from sklearn.naive_bayes import GaussianNB
nmodel = GaussianNB()
g_trained = nmodel.fit(xtrain, ytrain)
print(nmodel.score(xtest,ytest))
ytrain_prod=g_trained.predict(xtrain)
ytest_prod=g_trained.predict(xtest)
d=dia[["Pregnancies","Glucose","BloodPressure","SkinThickness","Insulin","BMI","DiabetesPedigreeFunction","Age","Outcome"]]
d.corr()
output = g_trained.predict([[10,101,76.0,48,180.0,32,0.171,63]])
print(output)
if output==1:
    print("Diabeties")
else:
    print("Healthy or normal person/lady")

"""**Recurrent Neural Networks (RNNs)**"""

pip install tensorflow

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Load the dataset
data = pd.read_csv('/content/drive/MyDrive/diabetes.csv')

# Split data into features and target
X = data.drop(columns='Outcome').values
y = data['Outcome'].values

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Convert labels to categorical
y_categorical = to_categorical(y)

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.3, random_state=42)

# Reshape for RNN [samples, timesteps, features]
X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

# Build the RNN model
model = Sequential()
model.add(SimpleRNN(50, activation='relu', input_shape=(1, X_train.shape[1])))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model and store the history
history = model.fit(X_train_reshaped, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X_test_reshaped, y_test)
print(f'Test loss: {loss:.4f}')
print(f'Test accuracy: {accuracy:.4f}')

# Accuracy chart
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

# Make predictions
predictions = model.predict(X_test_reshaped)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(y_test, axis=1)

# Confusion Matrix
cm = confusion_matrix(true_classes, predicted_classes)
cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Diabetes', 'Diabetes'])
cm_display.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

"""** Model Training**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
dia = pd.read_csv('/content/drive/MyDrive/diabetes.csv')

# Display basic information about the dataset
print(dia.info())
print(dia.head())

# Define features and target variable
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
target = 'Outcome'

X = dia[features]
y = dia[target]

# Check for missing values
print(X.isnull().sum())

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Initialize and train the Random Forest model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions and evaluate the model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy:.4f}')
print('Classification Report:')
print(report)

"""**Recursive Feature Elimination (RFE)**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
dia = pd.read_csv('/content/drive/MyDrive/diabetes.csv')

# Display basic information about the dataset
print(dia.info())
print(dia.head())

# Define features and target variable
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
target = 'Outcome'

X = dia[features]
y = dia[target]

# Check for missing values
print(X.isnull().sum())

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Initialize the SVM model
svm_model = SVC(kernel='linear', random_state=42)

# Initialize RFE with the SVM model
rfe = RFE(estimator=svm_model, n_features_to_select=5)  # You can adjust the number of features to select

# Fit RFE to the data
rfe.fit(X_train, y_train)

# Get the selected features
selected_features = [features[i] for i in range(len(features)) if rfe.support_[i]]
print(f'Selected features: {selected_features}')

# Transform the dataset to include only the selected features
X_train_rfe = rfe.transform(X_train)
X_test_rfe = rfe.transform(X_test)

# Train the SVM model with selected features
svm_model.fit(X_train_rfe, y_train)

# Make predictions and evaluate the model
y_pred = svm_model.predict(X_test_rfe)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f'Accuracy with RFE-selected features using SVM: {accuracy:.4f}')
print('Classification Report with RFE-selected features using SVM:')
print(report)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
dia = pd.read_csv('/content/drive/MyDrive/diabetes.csv')

# Display basic information about the dataset
print(dia.info())
print(dia.head())

# Define features and target variable
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
target = 'Outcome'

X = dia[features]
y = dia[target]

# Check for missing values
print(X.isnull().sum())

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Initialize the Gradient Boosting model
model = GradientBoostingClassifier(random_state=42)

# Initialize RFE with the Gradient Boosting model
rfe = RFE(estimator=model, n_features_to_select=5)  # Adjust the number of features to select

# Fit RFE to the data
rfe.fit(X_train, y_train)

# Get the selected features
selected_features = [features[i] for i in range(len(features)) if rfe.support_[i]]
print(f'Selected features: {selected_features}')

# Transform the dataset to include only the selected features
X_train_rfe = rfe.transform(X_train)
X_test_rfe = rfe.transform(X_test)

# Train the model with selected features
model.fit(X_train_rfe, y_train)

# Make predictions and evaluate the model
y_pred = model.predict(X_test_rfe)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f'Accuracy with RFE-selected features: {accuracy:.4f}')
print('Classification Report with RFE-selected features:')
print(report)

# Initialize the Random Forest model for feature selection
rf_model = RandomForestClassifier(random_state=42)

# Initialize RFE with the Random Forest model
rfe = RFE(estimator=rf_model, n_features_to_select=5)

# Fit RFE to the data
rfe.fit(X_train, y_train)

# Get the selected features
selected_features = [features[i] for i in range(len(features)) if rfe.support_[i]]
print(f'Selected features: {selected_features}')

# Transform the dataset to include only the selected features
X_train_rfe = rfe.transform(X_train)
X_test_rfe = rfe.transform(X_test)

from google.colab import drive
drive.mount('/content/drive')



import numpy as np

# Creating mixed dummy unseen data (some likely diabetic, some non-diabetic)
# The array consists of rows representing [Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age]

X_unseen_mixed = np.array([
    [2, 85, 60, 12, 0.0, 18.5, 0.1, 25]])


# Making predictions on the mixed unseen data using the trained model `rf`
y_pred_unseen_mixed = rf.predict(X_unseen_mixed)

# Output the predictions
print("Predictions on Unseen Data (Diabetic and Non-diabetic):")
print(y_pred_unseen_mixed)